{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probtorch\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the availability of CUDA\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder values for hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_FACTORS   = 50\n",
    "NUM_SAMPLES   = 10\n",
    "SOURCE_WEIGHT_STD_DEV = np.sqrt(2.0)\n",
    "SOURCE_WIDTH_STD_DEV  = np.sqrt(3.0)\n",
    "VOXEL_NOISE            = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here set some manually calibrated hyperparameter values.  In particular, ProbTorch uses standard deviations (σ) for its Normal distributions instead of variances (σ^2).\n",
    "\n",
    "**TODO**: switch over to log-widths rather than direct widths here\n",
    "\n",
    "**TODO**: fully switch over to standard deviations.  CTRL-F for \"variance\" and make sure it's gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our sample dataset\n",
    "dataset = sio.loadmat('s0.mat')\n",
    "\n",
    "# pull out the voxel activations and locations\n",
    "voxel_activations = torch.Tensor(dataset['data']).transpose(0, 1)\n",
    "voxel_locations = torch.Tensor(dataset['R'])\n",
    "\n",
    "# This could be a huge file.  Close it\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: move all of these global variables into a class, which can then be passed the dataset filename as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out relevant dimensions: the number of times-of-recording, and the number of voxels in each timewise \"slice\"\n",
    "num_times = voxel_activations.shape[0]\n",
    "num_voxels = voxel_activations.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate further hyperparameters from the dataset\n",
    "brain_center = torch.mean(voxel_locations, 0).unsqueeze(0)\n",
    "brain_center_variance = 10 * torch.var(voxel_locations, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations: V x 3\n",
    "# centers: S x K x 3\n",
    "# log_widths: S x K\n",
    "def radial_basis(locations, centers, log_widths, num_samples=NUM_SAMPLES, num_voxels=num_voxels):\n",
    "    # V x 3 -> S x 1 x V x 3\n",
    "    locations = locations.expand(num_samples, num_voxels, 3).unsqueeze(1)\n",
    "    # S x K x 3 -> S x K x 1 x 3  \n",
    "    centers = centers.unsqueeze(2)\n",
    "    # S x K x V x 3\n",
    "    delta2s = (locations - centers)**2\n",
    "    # S x K  -> S x K x 1\n",
    "    log_widths = log_widths.unsqueeze(2)\n",
    "    return torch.exp(-delta2s.sum(3) / torch.exp(log_widths))\n",
    "\n",
    "def free_energy(q, p, num_samples=NUM_SAMPLES):\n",
    "    # Remember: the Evidence Lower Bound is the negative free-energy\n",
    "    return -probtorch.objectives.montecarlo.elbo(q, p, sample_dim=0)\n",
    "\n",
    "def kl_divergence(q, p, num_samples=NUM_SAMPLES):\n",
    "    return probtorch.objectives.montecarlo.kl(q, p, sample_dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the radial basis functions so that the dimensions match up correctly and the math is as clear as possible, using elementwise tensor math everywhere.  Torch optimizers also seem to only minimize, so we negate the ELBO objective and call it the free-energy.\n",
    "\n",
    "The other objective functions are to check the noise and calibration on our optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFAEncoder(nn.Module):\n",
    "    def __init__(self, num_times=num_times, num_factors=NUM_FACTORS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self._num_times = num_times\n",
    "        self._num_factors = num_factors\n",
    "        \n",
    "        self._mean_weight = Parameter(torch.randn((self._num_times, self._num_factors)))\n",
    "        self._weight_variance = Parameter(torch.randn((self._num_times, self._num_factors)))\n",
    "        \n",
    "        self._mean_factor_center = Parameter(torch.randn((self._num_factors, 3)))\n",
    "        self._factor_center_variance = Parameter(torch.randn((self._num_factors, 3)))\n",
    "        \n",
    "        self._mean_factor_width = Parameter(torch.randn((self._num_factors)))\n",
    "        self._factor_width_variance = Parameter(torch.randn((self._num_factors)))\n",
    "\n",
    "    def forward(self, num_samples = NUM_SAMPLES):\n",
    "        q = probtorch.Trace()\n",
    "\n",
    "        mean_weight = self._mean_weight.expand(num_samples, self._num_times, self._num_factors)\n",
    "        weight_variance = self._weight_variance.expand(num_samples, self._num_times, self._num_factors)\n",
    "        \n",
    "        mean_factor_center = self._mean_factor_center.expand(num_samples, self._num_factors, 3)\n",
    "        factor_center_variance = self._factor_center_variance.expand(num_samples, self._num_factors, 3)\n",
    "        \n",
    "        mean_factor_width = self._mean_factor_width.expand(num_samples, self._num_factors)\n",
    "        factor_width_variance = self._factor_width_variance.expand(num_samples, self._num_factors)\n",
    "        \n",
    "        weights = q.normal(mean_weight, weight_variance, name='Weights')\n",
    "        \n",
    "        factor_centers = q.normal(mean_factor_center, factor_center_variance, name='FactorCenters')\n",
    "        factor_widths = q.normal(mean_factor_width, factor_width_variance, name='FactorWidths')\n",
    "        \n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Draw the `Parameter()` values here from the priors specified in the TFA paper rather than generating them from `torch.randn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFADecoder(nn.Module):\n",
    "    def __init__(self, num_times = num_times, num_factors = NUM_FACTORS, num_voxels = num_voxels):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self._num_times = num_times\n",
    "        self._num_factors = num_factors\n",
    "        self._num_voxels = num_voxels\n",
    "        \n",
    "        self._mean_weight = Variable(torch.zeros((self._num_times, self._num_factors)))\n",
    "        self._weight_variance = Variable(SOURCE_WEIGHT_STD_DEV * torch.ones((self._num_times, self._num_factors)))\n",
    "        \n",
    "        self._mean_factor_center = Variable(brain_center.expand(self._num_factors, 3) * torch.ones((self._num_factors, 3)))\n",
    "        self._factor_center_variance = Variable(brain_center_variance.expand(self._num_factors, 3) * torch.ones((self._num_factors, 3)))\n",
    "        \n",
    "        self._mean_factor_width = Variable(torch.ones((self._num_factors)))\n",
    "        self._factor_width_variance = Variable(SOURCE_WIDTH_STD_DEV * torch.ones((self._num_factors)))\n",
    "        \n",
    "        self._voxel_noise = Variable(VOXEL_NOISE * torch.ones(self._num_times, self._num_voxels))\n",
    "        \n",
    "    def forward(self, activations = voxel_activations, locations = voxel_locations, q=None):\n",
    "        p = probtorch.Trace()\n",
    "        \n",
    "        weights = p.normal(self._mean_weight, self._weight_variance, value=q['Weights'], name='Weights')\n",
    "        factor_centers = p.normal(self._mean_factor_center, self._factor_center_variance, value=q['FactorCenters'], name='FactorCenters')\n",
    "        factor_widths = p.normal(self._mean_factor_width, self._factor_width_variance, value=q['FactorWidths'], name='FactorWidths')\n",
    "        factors = radial_basis(locations, factor_centers, factor_widths, num_voxels = self._num_voxels)\n",
    "        observations = p.normal(torch.matmul(weights, factors), self._voxel_noise, value=activations, name='Y')\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = TFAEncoder()\n",
    "dec = TFADecoder()\n",
    "\n",
    "if CUDA:\n",
    "    enc.cuda()\n",
    "    dec.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(enc.parameters()), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(activations, locations, enc, dec, num_steps=10):\n",
    "    optimizer = torch.optim.Adam(list(enc.parameters()), lr=LEARNING_RATE)\n",
    "    if CUDA:\n",
    "            activations = activations.cuda()\n",
    "            locations = locations.cuda()\n",
    "\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "\n",
    "    free_energies = np.zeros(num_steps)\n",
    "    kls = np.zeros(num_steps)\n",
    "    for n in range(num_steps):\n",
    "        start = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        q = enc()\n",
    "        p = dec(activations=activations, locations=locations, q=q)\n",
    "        \n",
    "        free_energy_n = free_energy(q, p)\n",
    "        #kl = kl_divergence(q, p)\n",
    "        kl = 0\n",
    "\n",
    "        free_energy_n.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if CUDA:\n",
    "            free_energy_n = free_energy_n.cpu()\n",
    "            kl = kl.cpu()\n",
    "        free_energies[n] = free_energy_n.data.numpy()[0]\n",
    "        #kls[n] = kl.data.numpy()[0]\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print('[Epoch %d] (%ds) Posterior free-energy %.4e, Joint KL divergence %.4e' % (n + 1, end - start, free_energy_n, kl))\n",
    "\n",
    "    losses = np.vstack([free_energies, kls])\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 2] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 3] (0s) Posterior free-energy 1.1876e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 4] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 5] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 6] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 7] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 8] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 9] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 10] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 11] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 12] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 13] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 14] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 15] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 16] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 17] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 18] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 19] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 20] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 21] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 22] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 23] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 24] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 25] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 26] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 27] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 28] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 29] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 30] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 31] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 32] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 33] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 34] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 35] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 36] (0s) Posterior free-energy 1.1878e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 37] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 38] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 39] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 40] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 41] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 42] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 43] (0s) Posterior free-energy 1.2082e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 44] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 45] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 46] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 47] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 48] (0s) Posterior free-energy 1.1890e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 49] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 50] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 51] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 52] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 53] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 54] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 55] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 56] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 57] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 58] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 59] (0s) Posterior free-energy 1.1874e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 60] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 61] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 62] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 63] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 64] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 65] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 66] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 67] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 68] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 69] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 70] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 71] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 72] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 73] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 74] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 75] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 76] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 77] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 78] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 79] (0s) Posterior free-energy 1.1872e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 80] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 81] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 82] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 83] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 84] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 85] (0s) Posterior free-energy 1.1899e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 86] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 87] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 88] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 89] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 90] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 91] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 92] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 93] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 94] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 95] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 96] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 97] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 98] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 99] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n",
      "[Epoch 100] (0s) Posterior free-energy 1.1873e+07, Joint KL divergence 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "losses = train(Variable(voxel_activations), Variable(voxel_locations), enc, dec, num_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb157d83780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAG2CAYAAAATCaNwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJJBh6bqo8D4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb18449ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.plot(range(losses.shape[1]), losses[0,:], 'b')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.axes[0].set_xlabel('Epoch')\n",
    "fig.axes[0].set_ylabel('Free-energy / -ELBO (nats)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = enc()\n",
    "if CUDA:\n",
    "    q['Weights'].value.data.cpu()\n",
    "    q['FactorCenters'].value.data.cpu()\n",
    "    q['FactorWidths'].value.data.cpu()\n",
    "\n",
    "weights = q['Weights'].value.data.numpy()\n",
    "factor_centers = q['FactorCenters'].value.data.numpy()\n",
    "factor_widths = q['FactorWidths'].value.data.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
