{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import probtorch\n",
    "import scipy.io as sio\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the availability of CUDA\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder values for hyperparameters\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_FACTORS   = 50\n",
    "NUM_SAMPLES   = 10\n",
    "SOURCE_WEIGHT_VARIANCE = 2\n",
    "SOURCE_WIDTH_VARIANCE  = 3\n",
    "VOXEL_NOISE            = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our sample dataset\n",
    "dataset = sio.loadmat('s0.mat')\n",
    "\n",
    "# pull out the voxel activations and locations\n",
    "voxel_activations = torch.Tensor(dataset['data']).transpose(0, 1)\n",
    "voxel_locations = torch.Tensor(dataset['R'])\n",
    "\n",
    "# This could be a huge file.  Close it\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out relevant dimensions: the number of times-of-recording, and the number of voxels in each timewise \"slice\"\n",
    "num_times = voxel_activations.shape[0]\n",
    "num_voxels = voxel_activations.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate further hyperparameters from the dataset\n",
    "brain_center = torch.mean(voxel_locations, 0).unsqueeze(0)\n",
    "brain_center_variance = 10 * torch.var(voxel_locations, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_basis(locations, centers, distances, num_samples = NUM_SAMPLES, num_voxels = num_voxels):\n",
    "    locations = locations.unsqueeze(0).expand(num_samples, num_voxels, 3).unsqueeze(1)\n",
    "    centers = centers.unsqueeze(2)\n",
    "    distances = distances.unsqueeze(2)\n",
    "    \n",
    "    return torch.exp(((locations - centers)**2).sum(3) / -torch.exp(distances))\n",
    "\n",
    "def elbo(q, p, num_samples = NUM_SAMPLES):\n",
    "    # Remember: the Evidence Lower Bound is the negative free-energy/negative KL divergence\n",
    "    return -probtorch.objectives.montecarlo.kl(q, p, sample_dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFAEncoder(nn.Module):\n",
    "    def __init__(self, num_times = num_times, num_factors = NUM_FACTORS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self._num_times = num_times\n",
    "        self._num_factors = num_factors\n",
    "        \n",
    "        self._mean_weight = Parameter(torch.randn((self._num_times, self._num_factors)))\n",
    "        self._weight_variance = Parameter(torch.randn((self._num_times, self._num_factors)))\n",
    "        \n",
    "        self._mean_factor_center = Parameter(torch.randn((self._num_factors, 3)))\n",
    "        self._factor_center_variance = Parameter(torch.randn((self._num_factors, 3)))\n",
    "        \n",
    "        self._mean_factor_width = Parameter(torch.randn((self._num_factors)))\n",
    "        self._factor_width_variance = Parameter(torch.randn((self._num_factors)))\n",
    "\n",
    "    def forward(self, num_samples = NUM_SAMPLES):\n",
    "        q = probtorch.Trace()\n",
    "\n",
    "        mean_weight = self._mean_weight.expand(num_samples, self._num_times, self._num_factors)\n",
    "        weight_variance = self._weight_variance.expand(num_samples, self._num_times, self._num_factors)\n",
    "        \n",
    "        mean_factor_center = self._mean_factor_center.expand(num_samples, self._num_factors, 3)\n",
    "        factor_center_variance = self._factor_center_variance.expand(num_samples, self._num_factors, 3)\n",
    "        \n",
    "        mean_factor_width = self._mean_factor_width.expand(num_samples, self._num_factors)\n",
    "        factor_width_variance = self._factor_width_variance.expand(num_samples, self._num_factors)\n",
    "        \n",
    "        weights = q.normal(mean_weight, weight_variance, name='Weights')\n",
    "        \n",
    "        factor_centers = q.normal(mean_factor_center, factor_center_variance, name='FactorCenters')\n",
    "        factor_widths = q.normal(mean_factor_width, factor_width_variance, name='FactorWidths')\n",
    "        \n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFADecoder(nn.Module):\n",
    "    def __init__(self, num_times = num_times, num_factors = NUM_FACTORS, num_voxels = num_voxels):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self._num_times = num_times\n",
    "        self._num_factors = num_factors\n",
    "        self._num_voxels = num_voxels\n",
    "        \n",
    "        self._mean_weight = Parameter(torch.zeros((self._num_times, self._num_factors)))\n",
    "        self._weight_variance = Parameter(SOURCE_WEIGHT_VARIANCE * torch.ones((self._num_times, self._num_factors)))\n",
    "        \n",
    "        self._mean_factor_center = Parameter(brain_center.expand(self._num_factors, 3) * torch.ones((self._num_factors, 3)))\n",
    "        self._factor_center_variance = Parameter(brain_center_variance.expand(self._num_factors, 3) * torch.ones((self._num_factors, 3)))\n",
    "        \n",
    "        self._mean_factor_width = Parameter(torch.ones((self._num_factors)))\n",
    "        self._factor_width_variance = Parameter(SOURCE_WIDTH_VARIANCE * torch.ones((self._num_factors)))\n",
    "        \n",
    "        self._voxel_noise = Parameter(VOXEL_NOISE * torch.ones(self._num_times, self._num_voxels))\n",
    "        \n",
    "    def forward(self, activations = voxel_activations, locations = voxel_locations, q=None):\n",
    "        p = probtorch.Trace()\n",
    "        \n",
    "        weights = p.normal(self._mean_weight, self._weight_variance, value=q['Weights'], name='Weights')\n",
    "        factor_centers = p.normal(self._mean_factor_center, self._factor_center_variance, value=q['FactorCenters'], name='FactorCenters')\n",
    "        factor_widths = p.normal(self._mean_factor_width, self._factor_width_variance, value=q['FactorWidths'], name='FactorWidths')\n",
    "        factors = radial_basis(locations, factor_centers, factor_widths, num_voxels = self._num_voxels)\n",
    "        observations = p.normal(torch.matmul(weights, factors), self._voxel_noise, value=activations, name='Y')\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eli/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:87: UserWarning: \n",
      "    Found GPU0 GeForce GTX 1080 Ti which requires CUDA_VERSION >= 8000 for\n",
      "     optimal performance and fast startup time, but your PyTorch was compiled\n",
      "     with CUDA_VERSION 7050. Please install the correct PyTorch binary\n",
      "     using instructions from http://pytorch.org\n",
      "    \n",
      "  warnings.warn(error_str % (d, name, 8000, CUDA_VERSION))\n"
     ]
    }
   ],
   "source": [
    "enc = TFAEncoder()\n",
    "dec = TFADecoder()\n",
    "\n",
    "if CUDA:\n",
    "    enc.cuda()\n",
    "    dec.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(activations, locations, enc, dec, num_steps = 10):\n",
    "    optimizer = torch.optim.Adam(list(enc.parameters()), lr = LEARNING_RATE)\n",
    "    if CUDA:\n",
    "            activations = activations.cuda()\n",
    "            locations = locations.cuda()\n",
    "\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    \n",
    "    losses = np.zeros(num_steps)\n",
    "    for n in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        q = enc()\n",
    "        p = dec(activations = activations, locations = locations, q = q)\n",
    "        \n",
    "        loss = elbo(q, p)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if CUDA:\n",
    "            loss = loss.cpu()\n",
    "        losses[n] = loss.data.numpy()[0]\n",
    "        print(losses[n])\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17434.318359375\n",
      "-21401.673828125\n",
      "-25290.572265625\n",
      "-28538.748046875\n",
      "-31673.337890625\n",
      "-34475.75390625\n",
      "-36921.83203125\n",
      "-39085.265625\n",
      "-41075.375\n",
      "-42802.57421875\n"
     ]
    }
   ],
   "source": [
    "losses = train(Variable(voxel_activations), Variable(voxel_locations), enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    q = enc()\n",
    "    weights = q['Weights'].value.data.cpu().numpy()\n",
    "    factor_centers = q['FactorCenters'].value.data.cpu().numpy()\n",
    "    factor_widths = q['FactorWidths'].value.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
